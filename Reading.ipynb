{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reading.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9YvebYMVyd5jqMvWWTjlx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngeMervaneJdev/ML_AI_1/blob/main/Reading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(1) Quel type de méthode existait dans le domaine de la détection d'objets?\n",
        " * Fast-R-CNN\n",
        "\n",
        "  *Recent advances in object detection are driven by\n",
        "the success of region proposal methods (e.g., [4])\n",
        "and region-based convolutional neural networks (RCNNs) [5].*\n",
        "\n",
        "## (2) Il est dit \"Faster\" (plus rapide), mais quel mécanisme a été utilisé pour le rendre plus rapide ?\n",
        "* Region proposal methods typically rely on inexpensive features and economical inference schemes.\n",
        "Selective Search (extract from the pdf)\n",
        "\n",
        "##(3) En quoi la méthode en une étape est-elle différente de la méthode en deux étapes?\n",
        "   * One-stage class-specific detection only\n",
        "     the “proposals” are dense sliding windows of 3 scales and 3 aspect ratios\n",
        "   * Two-stage Consists of class-agnostic proposal & class-specific detection\n",
        "\n",
        "\n",
        " Page 10.\n",
        "\n",
        "##(4) Qu'est-ce que le RPN?\n",
        "  * A network that detects objects from the input image\n",
        "  * An RPN is a fully convolutional\n",
        "network that simultaneously predicts object bounds and objectness scores at each position\n",
        "  *Page 1.*\n",
        "\n",
        "##(5) Qu'est-ce que le RoI pooling?\n",
        " * RoI = Region of Interest\n",
        " * Pooling performed on the area of ​​interest (in this case, the area where the object candidate is detected). Maximum value pooling\n",
        "Since the input size to CNN can be unified, the resize process can be omitted.\n",
        "\n",
        " *Page 6 (iii) Non-approximate joint training*\n",
        "\n",
        "\n",
        "##(6) Quelle est la taille appropriée pour l'ancre?\n",
        "* An anchor is centered at the sliding window\n",
        "in question, and is associated with a scale and aspect\n",
        "ratio (Figure 3, left). By default we use 3 scales and\n",
        "3 aspect ratios, yielding k = 9 anchors at each sliding\n",
        "position. For a convolutional feature map of a size\n",
        "W × H (typically ∼2,400), there are W Hk anchors in\n",
        "total\n",
        "\n",
        " *Page 4*\n",
        "##(7) Quel type d'ensemble de données est utilisé et quel type de valeur d'indice est obtenu par rapport à la recherche précédente?\n",
        " * Dataset\n",
        "\n",
        "      *PASCAL VOC 2007*\n",
        "\n",
        "      *PASCAL VOC 2012*\n",
        "* indix: \n",
        "\n",
        "  *mean average precision*\n",
        "* Compare with Selective Search, Edge Boxes\n",
        "*We use\n",
        "VGG-16 to train the RPN, and still use the above\n",
        "detector of SS+ZF. The mAP improves from 56.8%\n",
        "(using RPN+ZF) to 59.2% (using RPN+VGG). This is a\n",
        "promising result, because it suggests that the proposal\n",
        "quality of RPN+VGG is better than that of RPN+ZF.\n",
        "Because proposals of RPN+ZF are competitive with\n",
        "SS (both are 58.7% when consistently used for training\n",
        "and testing), we may expect RPN+VGG to be better\n",
        "than SS. Page 8*\n",
        "##(8) ( Questions avancée) Comment Faster R-CNN est-il cité dans l'article sur la détection d'objets plus récent que Faster R-CNN?\n",
        "* Faster R-CNN is a deep convolutional network used for object detection, that appears to the user as a single, end-to-end, unified network. The network can accurately and quickly predict the locations of different objects\n",
        "[link](https://blog.paperspace.com/faster-r-cnn-explained-object-detection/)"
      ],
      "metadata": {
        "id": "fHtAOdaPc0IC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btAImRHaaU13"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}