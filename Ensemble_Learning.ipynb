{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPC1UQg7nx+ZUTg0+SHkOg/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngeMervaneJdev/ML_AI_1/blob/main/Ensemble_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "129bTW_fZdFU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b3qVhFmve6fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo13vLr6TvCF",
        "outputId": "3ee8896c-04ba-4daa-c508-35dd01d24226"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([208500, 181500, 223500, ..., 266500, 142125, 147500])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data=pd.read_csv(\"train.csv\")\n",
        "test=pd.read_csv(\"test.csv\")\n",
        "X=np.array(data[['GrLivArea',\"YearBuilt\"]])\n",
        "y=np.array(data.SalePrice)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyarTFf1ZyZr",
        "outputId": "6c00c287-a1e8-4de2-eb52-d0f3e07b066e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1710, 2003],\n",
              "       [1262, 1976],\n",
              "       [1786, 2001],\n",
              "       ...,\n",
              "       [2340, 1941],\n",
              "       [1078, 1950],\n",
              "       [1256, 1965]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Probleme 1"
      ],
      "metadata": {
        "id": "VUuwO60TfXyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X,y,random_state=42)"
      ],
      "metadata": {
        "id": "JgUDXF1mgk7t"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf1 = LogisticRegression(multi_class='multinomial', random_state=1,solver='lbfgs', max_iter=50)\n",
        "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
        "clf3 = GaussianNB()"
      ],
      "metadata": {
        "id": "DMfqEF1fe5wp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models=[clf1,\n",
        "clf2, clf3]"
      ],
      "metadata": {
        "id": "-Yfozxf0v5nK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1"
      ],
      "metadata": {
        "id": "_SgSgW5SzbeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first \n",
        "predictions=[]\n",
        "for ml in models:\n",
        "  predictions.append(ml.fit(X_train,y_train).predict(X_test))\n",
        "predictions= np.array(predictions)\n",
        "MSE = mean_squared_error(y_test,np.mean(predictions,axis=0))\n",
        "print('MSE : '+str(MSE))\n",
        "\n",
        "eclf1 = VotingClassifier(estimators=[ ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
        "eclf1 = eclf1.fit(X_train, y_train)\n",
        "y_pred=eclf1.predict(X_test)"
      ],
      "metadata": {
        "id": "3dkMyhngn_j8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a833d29f-fc13-492c-c476-346050b35998"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE : 2286391853.0849314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2"
      ],
      "metadata": {
        "id": "jLsgyyaXzXNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#second\n",
        "models[2]=SVR();\n",
        "predictions=[]\n",
        "for ml in models:\n",
        "  predictions.append(ml.fit(X_train,y_train).predict(X_test))\n",
        "predictions= np.array(predictions)\n",
        "MSE = mean_squared_error(y_test,np.mean(predictions,axis=0))\n",
        "print('MSE : '+str(MSE))\n",
        "\n",
        "eclf1 = VotingClassifier(estimators=[ ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
        "eclf1 = eclf1.fit(X_train, y_train)\n",
        "y_pred=eclf1.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lztLV2OOzScP",
        "outputId": "fede18c9-6b4d-497d-dce2-42ca6a5b77ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE : 3121982673.3040857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3"
      ],
      "metadata": {
        "id": "5thxSahxzZox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#third\n",
        "models[1]=DecisionTreeClassifier();\n",
        "models[2]=SVR();\n",
        "predictions=[]\n",
        "for ml in models:\n",
        "  predictions.append(ml.fit(X_train,y_train).predict(X_test))\n",
        "predictions= np.array(predictions)\n",
        "MSE = mean_squared_error(y_test,np.mean(predictions,axis=0))\n",
        "print('MSE : '+str(MSE))\n",
        "\n",
        "eclf1 = VotingClassifier(estimators=[ ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
        "eclf1 = eclf1.fit(X_train, y_train)\n",
        "y_pred=eclf1.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ02VZDizVxR",
        "outputId": "bda54b82-7aa9-47ce-ac2e-14a557a145a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE : 3263714040.9951105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probleme 2"
      ],
      "metadata": {
        "id": "yMkuYoq_XVuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_algorithms = [LogisticRegression(), DecisionTreeClassifier(),KNeighborsClassifier(n_neighbors=3)] #for classification\n",
        "\n",
        "def bagging(X,y,models):\n",
        "  stacking_train_dataset = []\n",
        "  for model in models:\n",
        "     X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,shuffle=True)    \n",
        "     stacking_train_dataset.append(model.fit(X_train,y_train).predict(X_test))\n",
        "  return stacking_train_dataset;\n",
        "\n",
        "bagging(X,y,base_algorithms)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zehSIWCvluHc",
        "outputId": "46b60a68-31d6-43f4-b5fb-fb99c9f5de49"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([110000, 290000, 110000, 190000, 190000,  80000, 190000, 140000,\n",
              "         80000, 140000, 140000, 110000, 110000, 140000, 190000, 110000,\n",
              "        190000, 110000, 110000, 140000, 190000, 140000, 140000, 110000,\n",
              "        140000, 140000, 140000, 110000, 140000, 140000, 140000, 190000,\n",
              "        485000, 110000, 190000, 110000, 190000, 190000, 290000, 110000,\n",
              "        140000, 160000, 110000, 190000, 110000, 250000, 110000, 110000,\n",
              "        250000, 140000, 110000, 140000, 140000, 290000, 110000, 190000,\n",
              "        190000, 110000, 110000, 110000,  39300, 140000, 290000, 140000,\n",
              "        190000, 160000, 110000, 160000, 110000, 140000, 140000, 140000,\n",
              "        110000, 110000, 250000, 140000, 250000, 250000, 110000,  80000,\n",
              "        110000, 110000, 110000, 110000, 140000, 190000, 190000, 140000,\n",
              "        110000, 140000, 140000, 190000,  80000, 290000, 190000, 140000,\n",
              "        140000, 140000, 140000, 250000, 190000, 190000, 160000, 110000,\n",
              "        140000, 140000, 110000, 190000, 110000, 160000,  80000, 110000,\n",
              "        110000, 140000, 190000,  80000, 110000, 110000, 190000, 190000,\n",
              "         80000, 110000, 140000, 190000, 140000, 110000, 160000, 110000,\n",
              "        110000, 190000, 140000, 190000, 190000, 250000,  39300, 190000,\n",
              "        190000, 110000, 190000, 745000, 290000, 110000, 190000, 190000,\n",
              "        110000, 110000, 160000, 140000,  80000, 110000, 140000, 140000,\n",
              "        290000, 250000, 110000, 190000, 140000, 140000,  80000, 110000,\n",
              "        140000, 110000, 190000, 140000, 140000, 190000, 190000, 290000,\n",
              "        290000, 290000, 190000, 110000, 140000, 140000, 290000, 190000,\n",
              "        140000, 190000, 140000, 140000, 140000, 110000, 110000, 140000,\n",
              "        190000, 190000, 190000, 140000, 140000, 110000, 140000, 110000,\n",
              "        140000, 110000, 140000, 160000, 140000, 140000, 190000, 140000,\n",
              "        140000, 140000, 140000, 290000, 140000, 110000, 190000, 110000,\n",
              "        190000, 110000, 160000, 140000, 140000, 140000, 140000, 140000,\n",
              "        140000, 110000, 140000, 190000, 110000, 140000, 190000, 110000,\n",
              "        140000, 140000, 110000, 110000, 190000, 140000, 110000, 140000,\n",
              "        110000, 140000, 190000, 140000, 140000, 110000, 160000, 110000,\n",
              "         80000, 290000, 190000, 290000, 190000, 140000, 140000, 110000,\n",
              "        110000,  80000, 190000, 140000, 140000,  80000, 110000, 110000,\n",
              "        140000, 140000, 140000, 160000, 190000, 140000, 110000, 190000,\n",
              "        190000, 190000, 140000, 110000, 110000, 140000, 160000, 140000,\n",
              "        190000, 110000, 140000, 110000, 190000, 190000, 140000, 140000,\n",
              "        190000,  80000, 140000,  80000, 190000, 140000, 190000, 110000,\n",
              "        140000, 140000, 140000, 110000, 140000, 140000,  80000, 190000,\n",
              "        190000, 110000, 140000, 140000, 140000, 140000, 110000, 110000,\n",
              "        190000, 190000, 110000, 160000, 250000, 110000, 140000, 190000,\n",
              "         80000, 290000, 190000, 140000, 140000, 140000, 190000, 110000,\n",
              "        140000, 140000, 140000, 110000, 190000, 190000, 110000, 140000,\n",
              "        140000, 110000, 140000, 140000,  80000, 140000, 140000, 110000,\n",
              "        140000, 140000, 110000, 140000, 190000, 110000, 190000, 140000,\n",
              "        190000, 190000, 190000, 110000, 290000, 110000, 290000, 290000,\n",
              "        190000, 140000, 190000, 110000, 110000, 110000, 190000, 160000,\n",
              "        190000, 140000, 160000, 190000, 110000]),\n",
              " array([156000, 290000, 102000, 160000, 295493,  81000, 130000, 179900,\n",
              "         80000, 130000, 125000, 129000, 106500, 259000, 200000, 109000,\n",
              "        196500, 176000, 108500, 180000, 230000, 287090, 163990, 112000,\n",
              "        170000, 173000, 224000,  82000, 236500, 202500, 116000, 200000,\n",
              "        259500, 112000, 250000, 145000, 177000, 198500, 260000, 115000,\n",
              "        134900, 228000, 143250, 372500, 178400, 265979, 147000, 109900,\n",
              "        255900, 140000,  92900, 215000, 181000, 299800, 141000, 318000,\n",
              "        231500, 160000, 125000, 115000,  60000, 142000, 354000, 174000,\n",
              "        226700, 137900, 108000, 255900, 123600, 177000, 118964, 143000,\n",
              "        112500,  92900, 325300, 245500, 222000, 260000, 132500, 133000,\n",
              "         94500, 101000, 137000, 119750, 171750, 141500, 252000, 179900,\n",
              "        141000, 172785, 152000, 143000, 138000, 278000, 175000, 164990,\n",
              "        137450, 174000, 179665, 142953, 135000, 223500, 294000, 119000,\n",
              "        182900, 140000, 180000, 164000, 123600, 187500, 106500, 152000,\n",
              "        132250, 115000, 211000, 120500, 116000,  97000, 210000, 154000,\n",
              "        125000, 141000, 214000, 180500,  82500, 117500, 258000,  87000,\n",
              "        145000, 135000, 227000, 423000, 204750, 118500,  72500, 255500,\n",
              "        306000, 110000, 195000, 625000, 290000, 112000, 164000, 144000,\n",
              "        135000, 122000, 234000, 189000, 133000,  58500, 125000, 164500,\n",
              "        277000, 242000, 101000, 165150, 145000,  93000,  34900, 139950,\n",
              "        194500, 151000, 392500, 207500, 110000, 289000, 269790, 303477,\n",
              "        437154, 266500, 198500, 115000, 152000, 171000, 260000, 140000,\n",
              "        139500, 324000, 127500, 227000, 147500,  82000, 128000, 128500,\n",
              "        216500, 140000, 200000, 179665, 202665,  88000, 125000, 113000,\n",
              "         76500, 125000, 164990, 145000, 167240, 112000, 204000,  98000,\n",
              "        179900, 168500,  98000, 336000, 162000, 125000, 301500, 160000,\n",
              "        140200, 100000, 262280, 179200, 142000, 177000,  93000, 245000,\n",
              "        167500, 139950, 137500, 190000, 123000, 176432, 205000,  95000,\n",
              "        282922, 134450, 120000, 102000, 143000,  81000, 110500, 187500,\n",
              "        127500, 139000, 215000, 153900, 206000, 123600, 211000, 140000,\n",
              "         52000, 185000, 204000, 424870, 197500, 112000, 181900, 145000,\n",
              "        146800, 132000, 315000, 163900, 177500,  34900, 154000, 140000,\n",
              "        103000, 179200, 178000, 207500, 281000, 151000, 123000, 178000,\n",
              "        188000, 339750, 181000, 131500, 135000, 170000, 415298, 181000,\n",
              "        281000, 148000,  98600, 149000, 130000, 339750, 185000, 152000,\n",
              "        223500,  80000, 232000, 109500, 255500, 167000, 221000, 155000,\n",
              "        220000, 163990,  98000, 120500, 153000, 168000,  55000, 157000,\n",
              "        144000, 123000, 277500, 120000, 182900, 174000, 109900, 145000,\n",
              "        181000, 165000, 174900, 255900, 225000, 115000, 150000, 202500,\n",
              "         76000, 262500, 152000, 174000, 151000, 171900, 177000,  90000,\n",
              "        215200,  91500, 135000,  88000, 228000, 143000, 137000, 176432,\n",
              "        177500, 120500, 124000,  93000, 138000, 180000, 250580, 132000,\n",
              "        116000, 170000, 110500, 227680, 262000,  82000, 137000, 186700,\n",
              "        326000, 378500, 231500,  85500, 262500,  94750, 107500, 342643,\n",
              "        173000, 179200, 318000, 106500, 132500,  85000, 173000, 271000,\n",
              "        187500, 151000, 239686, 230000, 139950]),\n",
              " array([128000, 190000,  85000, 140000, 221500,  80000, 124500, 148500,\n",
              "         80000,  93000, 125000, 112500,  61000, 214000, 200000,  80000,\n",
              "        185000, 118000,  85000, 174000, 131500, 193000, 174000,  93000,\n",
              "        170000, 162000, 179000, 110500, 220000, 179000,  87000, 222500,\n",
              "        197000, 111000, 173000, 139950, 137000, 198500, 290000, 106500,\n",
              "        120000, 228000, 108000, 222500,  89500, 118500, 142000,  94750,\n",
              "        230000,  98000, 108000, 154000, 106000, 272000, 141000, 190000,\n",
              "        204750, 125000, 125000, 105500,  60000, 142000, 281213, 181000,\n",
              "        212000, 226000,  90000, 258000, 123600, 176000, 118964,  91500,\n",
              "        114500,  92900, 285000, 179200, 315750, 260000,  82000, 110000,\n",
              "         85400,  55000, 132500, 105000,  82500, 133000, 230500, 148500,\n",
              "        141000, 172785, 152000, 143000, 112000, 299800, 110000, 176432,\n",
              "        141500, 163990, 173900, 262280, 100000, 212000, 142953,  82500,\n",
              "        150000, 135000, 118500, 150900, 123600, 187500,  87000, 148000,\n",
              "        132250, 115000, 147000,  87000, 110000,  97000, 194500, 154000,\n",
              "        125000, 141000, 178000, 143000,  82500,  93000, 258000,  80000,\n",
              "        145000, 100000, 227000, 222500, 204750, 118500,  39300, 196500,\n",
              "        200000, 108000, 165400, 184750, 250000, 112500, 150900, 144000,\n",
              "        109000, 122000, 129500, 170000, 110000,  58500,  78000,  97000,\n",
              "        151400, 225000,  55000, 140000, 145000, 145250,  80000, 129000,\n",
              "        194000, 146800, 248900,  98000, 102000, 131500, 195000, 333168,\n",
              "        272000, 129000, 195000, 106500, 115000, 155000, 272000, 124000,\n",
              "        139500, 196500, 127500, 168000, 155000,  98300, 128000,  93000,\n",
              "        225000, 135900, 200000, 173900, 185850,  88000, 125000,  55000,\n",
              "         76500, 125000, 164990, 145000, 167240, 107000, 225000,  98000,\n",
              "        118964, 174000,  98000, 260000, 179000, 106000, 222500, 129000,\n",
              "        117000, 100000, 142953,  90000,  98600, 168500, 130000, 175900,\n",
              "        156932, 129000, 137500, 150900, 123000, 162000, 135000, 100000,\n",
              "        192000, 102000,  96500,  37900, 139000,  81000,  80000, 187500,\n",
              "        115000,  98600, 190000,  89500, 178000, 123600, 211000,  99500,\n",
              "         34900, 197000, 164000, 272000, 178000,  98000, 168000, 125000,\n",
              "        142000,  87000, 216837, 168500, 139500,  52500, 148000, 140000,\n",
              "        103000, 106000, 178000, 228000, 269500, 113000, 123000, 175000,\n",
              "        190000, 226000, 180000, 131500,  80000, 170000, 200000, 180000,\n",
              "        269500, 139000,  91500, 132500, 130000, 200000, 127000, 140200,\n",
              "        212000,  80000, 232000,  55000, 196500, 167000, 216837, 100000,\n",
              "        177000, 163990, 149000,  97000, 123000, 168000,  55000, 129900,\n",
              "        144000, 123000, 201000,  96500,  82500, 173900, 125000,  88000,\n",
              "        181000, 165000, 154000, 258000, 142953, 105500, 179900, 135000,\n",
              "         76000, 190000, 140200, 174000, 151000, 160000, 170000,  90000,\n",
              "        173900,  91500, 132000,  58500, 136905, 143000,  88000, 176485,\n",
              "        127000,  97000, 113000,  93000, 112000, 179000, 165000, 128000,\n",
              "         87000, 125000,  55000, 179600, 212000, 110500, 137000, 118964,\n",
              "        200000, 305900, 186500,  37900, 190000,  94750, 250000, 260000,\n",
              "        173000, 112000, 224500,  94750,  80000,  85000, 173000, 238000,\n",
              "        144000, 113000, 280000, 189000, 129000])]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Probleme 3"
      ],
      "metadata": {
        "id": "wJ14G6tfKVkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test=train_test_split(X,y,random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3,random_state=23)"
      ],
      "metadata": {
        "id": "yUbHG9mjhsnl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_level_1( final_learner, train_meta_model, test_meta_model):\n",
        "    # Train is carried out with final learner or meta model\n",
        "    final_learner.fit(train_meta_model, y_val)\n",
        "\n",
        "    # Getting train and test accuracies from meta_model\n",
        "    print(f\"Train accuracy: {final_learner.score(train_meta_model, y_val)}\")\n",
        "    print(f\"Test accuracy: {final_learner.score(test_meta_model, y_test)}\")"
      ],
      "metadata": {
        "id": "2TgzF1s7xrZ7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_level_0( clf):\n",
        "        # Train with base x_train\n",
        "        clf.fit(x_train, y_train)\n",
        "\n",
        "        # Generate predictions for the holdout set (validation)\n",
        "        # These predictions will build the input for the meta model\n",
        "        val_predictions = clf.predict(x_val)\n",
        "\n",
        "        # Generate predictions for original test set\n",
        "        # These predictions will be used to test the meta model\n",
        "        test_predictions = clf.predict(x_test)\n",
        "\n",
        "        return val_predictions, test_predictions"
      ],
      "metadata": {
        "id": "iv-Cg65HKmqD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weak_learners = [('dt', DecisionTreeClassifier()),('knn', KNeighborsClassifier()),('rf', RandomForestClassifier()),('gn', GaussianNB())]\n",
        "\n",
        "# Final learner or meta model\n",
        "final_learner = LogisticRegression()\n",
        "\n",
        "train_meta_model = None\n",
        "test_meta_model = None\n",
        "\n",
        "# Start stacking\n",
        "for clf_id, clf in weak_learners:\n",
        "\n",
        "    # Predictions for each classifier based on k-fold\n",
        "    val_predictions, test_predictions = train_level_0(clf)\n",
        "\n",
        "    # Stack predictions which will form \n",
        "    # the input data for the data model\n",
        "    if isinstance(train_meta_model, np.ndarray):\n",
        "        train_meta_model = np.vstack((train_meta_model, val_predictions))\n",
        "    else:\n",
        "        train_meta_model = val_predictions\n",
        "\n",
        "    # Stack predictions from test set\n",
        "    # which will form test data for meta model\n",
        "    if isinstance(test_meta_model, np.ndarray):\n",
        "        test_meta_model = np.vstack((test_meta_model, test_predictions))\n",
        "    else:\n",
        "        test_meta_model = test_predictions\n",
        "\n",
        "# Transpose train_meta_model\n",
        "train_meta_model = train_meta_model.T\n",
        "\n",
        "# Transpose test_meta_model\n",
        "test_meta_model = test_meta_model.T\n",
        "\n",
        "# Training level 1\n",
        "train_level_1(final_learner, train_meta_model, test_meta_model)"
      ],
      "metadata": {
        "id": "KJtse2zoKuj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35506e77-6fee-40da-ec8f-58ac6ae50401"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.1762917933130699\n",
            "Test accuracy: 0.005479452054794521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    }
  ]
}