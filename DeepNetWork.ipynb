{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepNetWork.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOb0IW4d30Mb8E69g7QNqTg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngeMervaneJdev/ML_AI_1/blob/main/DeepNetWork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problème 1] Classification des couches entièrement connectées"
      ],
      "metadata": {
        "id": "jzkTd2znONnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "CDLCbdERfQqo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NJKoc6dEOHh6"
      },
      "outputs": [],
      "source": [
        "class FC:\n",
        "    \"\"\"\n",
        "    ノード数n_nodes1からn_nodes2への全結合層\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes1 : int\n",
        "      前の層のノード数\n",
        "    n_nodes2 : int\n",
        "      後の層のノード数\n",
        "    initializer : インスタンス\n",
        "        初期化方法のインスタンス\n",
        "    optimizer : インスタンス\n",
        "        最適化手法のインスタンス\n",
        "    \"\"\"\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = initializer.B(n_nodes2)\n",
        "\n",
        "    \n",
        "    def forward(self, Z1):\n",
        "        self.Z = Z1.copy()\n",
        "        Z2 = np.dot(Z1, self.W) + self.B\n",
        "        \n",
        "        return Z2\n",
        "    \n",
        "    \n",
        "    def backward(self, dA):\n",
        "        self.dB = dA \n",
        "        self.dW = np.dot(self.Z.T, dA) \n",
        "        dZ = np.dot(dA, self.W.T) \n",
        "        \n",
        "        self = self.optimizer.update(self)\n",
        "        \n",
        "        return dZ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problème 2] Classer la méthode d'initialisation"
      ],
      "metadata": {
        "id": "vPDRw4uaO9W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializer:\n",
        "    \"\"\"\n",
        "    Simple initialization with Gaussian distribution\n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      Standard deviation of Gaussian distribution\n",
        "    \"\"\"\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \"\"\"\n",
        "        Weight initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes1 : int\n",
        "          Number of nodes in the previous layer\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in the later layer\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        W :\n",
        "        \"\"\"\n",
        "        W=self.sigma * np.random.randn(n_nodes1, n_nodes2) \n",
        "        pass\n",
        "        return W\n",
        "    def B(self, n_nodes2):\n",
        "        \"\"\"\n",
        "        Bias initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in the later layer\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        B :\n",
        "        \"\"\"\n",
        "        B=np.zeros(n_nodes2)\n",
        "        pass\n",
        "        return B"
      ],
      "metadata": {
        "id": "B0ddxUt0PDTq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problème 3] Classer les méthodes d'optimisation"
      ],
      "metadata": {
        "id": "eu2Icb6MPXcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    \"\"\"\n",
        "    Stochastic gradient descent\n",
        "    Parameters\n",
        "    ----------\n",
        "    lr : Learning rate\n",
        "    \"\"\"\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "        \"\"\"\n",
        "        Update weights and biases for a layer\n",
        "        Parameters\n",
        "        ----------\n",
        "        layer : Instance of the layer before update\n",
        "        \"\"\"\n",
        "        ## layer.dB=partial derivatives of loss\n",
        "        layer.W -= self.lr* layer.dW / layer.dB.shape[0] #(n_nodes1, n_nodes2)\n",
        "        layer.B -= self.lr* layer.dB.mean(axis=0) #(n_nodes2)"
      ],
      "metadata": {
        "id": "3ibaLyrjTRRx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problème 4] Classer les fonctions d'activation"
      ],
      "metadata": {
        "id": "_K3AyMC5XJ7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o5uobhsDpPft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax:\n",
        "    def __init__(self):\n",
        "        self.Z = None\n",
        "    \n",
        "    \n",
        "    def forward(self, A):\n",
        "        c = np.max(A)\n",
        "        exp_A = np.exp(A - c)\n",
        "        sum_exp_A = np.sum(exp_A, axis=1).reshape(-1, 1)\n",
        "\n",
        "        self.Z = exp_A / sum_exp_A\n",
        "        \n",
        "        return self.Z\n",
        "\n",
        "    \n",
        "    def backward(self, y):\n",
        "        loss_sum = np.sum(y * np.log(self.Z), axis=1)\n",
        "        loss = -np.mean(loss_sum)\n",
        "        \n",
        "        dA = self.Z - y\n",
        "        \n",
        "        return dA, loss"
      ],
      "metadata": {
        "id": "MAikGTQipQDi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.Z = None \n",
        "    def forward(self, A):\n",
        "        self.Z = 1 / (1 + np.exp(-A))\n",
        "        return self.Z\n",
        "    def backward(self, dZ):\n",
        "        dA = dZ * (1 - self.Z) * self.Z\n",
        "        return dA"
      ],
      "metadata": {
        "id": "HE4XqQwVZV3b"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tanh:\n",
        "    def __init__(self):\n",
        "        self.Z = None\n",
        "    \n",
        "    def forward(self, A):\n",
        "        self.Z =  np.tanh(A)\n",
        "        \n",
        "        return  self.Z\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        dA = dZ * (1 - self.Z**2)\n",
        "        \n",
        "        return dA"
      ],
      "metadata": {
        "id": "qG48zCD3fH44"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problem 5] ReLU class creation"
      ],
      "metadata": {
        "id": "LSJYwZFpbVQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.X = None\n",
        "    def forward(self, A):\n",
        "        self.X = A.copy()\n",
        "        Z = np.maximum(0, A)\n",
        "        return Z\n",
        "    def backward(self, dZ):\n",
        "        dA = np.where(self.X > 0, dZ, 0)\n",
        "        return dA"
      ],
      "metadata": {
        "id": "pohMW_q5cQsC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problem 6] Initial value of weight"
      ],
      "metadata": {
        "id": "aAZTaYD4g8Fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XavierInitializer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = np.random.randn(n_nodes1, n_nodes2) / np.sqrt(n_nodes1)\n",
        "        return W\n",
        "    \n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        B = np.zeros(n_nodes2) #(n_nodes2)\n",
        "        return B"
      ],
      "metadata": {
        "id": "6SnNdLFwg9Q2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HeInitializer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = np.random.randn(n_nodes1, n_nodes2) * np.sqrt(2 / n_nodes1)\n",
        "    \n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        B = np.zeros(n_nodes2) \n",
        "        \n",
        "        return B"
      ],
      "metadata": {
        "id": "rO7CR8-phfN0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problem 7] Optimization method"
      ],
      "metadata": {
        "id": "dx-Exo0jhmhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr \n",
        "        self.H_W= None \n",
        "        self.H_B = None\n",
        "\n",
        "    def update(self, layer):\n",
        "        if self.H_W is None:\n",
        "            self.H_W = np.zeros(layer.W.shape)\n",
        "        if self.H_B is None:\n",
        "            self.H_B = np.zeros(layer.B.shape)\n",
        "        \n",
        "        self.H_W += (layer.dW / layer.dB.shape[0]) ** 2 \n",
        "        self.H_B += (layer.dB.mean(axis=0)) **2\n",
        "        layer.W -= self.alpha / np.sqrt(self.H_W + 1e-7) * layer.dW / layer.dB.shape[0] \n",
        "        layer.B -= self.alpha / np.sqrt(self.H_B + 1e-7) * layer.dB.mean(axis=0) \n",
        "        \n",
        "        return layer"
      ],
      "metadata": {
        "id": "s_DpvlN8h6wW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problem 8] Class completion"
      ],
      "metadata": {
        "id": "HKrmcG3pk-lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      学習データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]        \n",
        "\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]"
      ],
      "metadata": {
        "id": "I3M2NXYcnDwK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier():\n",
        "    \"\"\"\n",
        "    ニューラルネットワーク分類器\n",
        "\n",
        "    Parameters\n",
        "    --------------\n",
        "    epoc : int\n",
        "        エポック数\n",
        "    activaiton : {'sigmoid', 'tanh', 'relu'} default 'relu'\n",
        "        活性化関数の種類\n",
        "    solver :  {'sgd', 'adagrad'}, default 'adam'\n",
        "        最適化手法の種類\n",
        "    lr : float\n",
        "        学習率\n",
        "    batch_size : int\n",
        "        バッチサイズ\n",
        "    initial : {'simple', 'xavier', 'he'} default 'he'\n",
        "        重みの初期化方法\n",
        "    sigma : float\n",
        "        重みパラメータ(ガウス分布の標準偏差)\n",
        "    n_nodes1 : int\n",
        "        1層目の数\n",
        "    n_nodes2 : int\n",
        "        2層目の数\n",
        "    n_output : int\n",
        "        出力層の数\n",
        "    verbose : bool\n",
        "        学習過程の出力の有無\n",
        "        \n",
        "    Attributes\n",
        "    -------------\n",
        "    FC1 :  インスタンス\n",
        "        結合層のインスタンス\n",
        "    FC2 :   インスタンス\n",
        "        結合層のインスタンス\n",
        "    FC3 :   インスタンス\n",
        "        結合層のインスタンス\n",
        "    activation1 : インスタンス\n",
        "        活性化関数のインスタンス\n",
        "    activation2 : インスタンス\n",
        "        活性化関数のインスタンス\n",
        "    activation3 : インスタンス\n",
        "        活性化関数のインスタンス\n",
        "    loss_list : list\n",
        "        学習用データのエポックごとの損失を記録するリスト\n",
        "     mini_loss_list : list\n",
        "        学習用データのイテレーションごとの損失を記録するリスト   \n",
        "    val_loss_list : list\n",
        "        検証用データのエポックごとの損失を記録するリスト\n",
        "    mini_val_loss_list : list\n",
        "        検証用データのイテレーションごとの損失を記録するリスト        \n",
        "    \"\"\"\n",
        "    def __init__(self, epoc=20, activation='relu', solver='adagrad', lr=0.005,\n",
        "                             batch_size=10, initial='he', sigma=0.01, n_nodes1=400, \n",
        "                             n_nodes2=200, verbose=True):\n",
        "        self.epoc=epoc              \n",
        "        self.activation= activation     \n",
        "        self.solver= solver            \n",
        "        self.lr= lr             \n",
        "        self.batch_size = batch_size   \n",
        "        self.initial = initial             \n",
        "        self.sigma = sigma            \n",
        "        self.n_nodes1= n_nodes1    \n",
        "        self.n_nodes2= n_nodes2    \n",
        "        self.verbose= verbose \n",
        "        self.val_is_true = False \n",
        "        self.FC1=None \n",
        "        self.FC2= None \n",
        "        self.FC3= None \n",
        "        self.activation1= None\n",
        "        self.activation2= None\n",
        "        self.activation3= None\n",
        "        self.loss_list= None \n",
        "        self.mini_loss_list = None        \n",
        "        self.val_loss_list= None\n",
        "        self.mini_val_loss_list= None \n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        if X.ndim == 1:\n",
        "            X = X[:, np.newaxis]\n",
        "        if y.ndim == 1:\n",
        "            y = y[:, np.newaxis]\n",
        "            \n",
        "        n_output = np.unique(y).shape[0]\n",
        "        y_onehot = self._one_hot(y, n_output)\n",
        "        \n",
        "        train_mini_batch = GetMiniBatch(X, y_onehot, self.batch_size)\n",
        " \n",
        "        if X_val is not None and y_val is not None:\n",
        "            \n",
        "            if X.ndim == 1:\n",
        "                X_val = X_val[:, np.newaxis]\n",
        "            if y_val.ndim == 1:\n",
        "                y_val = y_val[:, np.newaxis]\n",
        "\n",
        "            y_val_onehot = self._one_hot(y_val, n_output) \n",
        "            test_mini_batch = GetMiniBatch(X_val, y_val_onehot)\n",
        "        \n",
        "        \n",
        "        # Activation\n",
        "        if self.activation == 'sigmoid':\n",
        "            activate1 = Sigmoid()\n",
        "            activate2 = Sigmoid()\n",
        "        elif self.activation == 'tanh':\n",
        "            activate1 = Tanh()\n",
        "            activate2 = Tanh()\n",
        "        elif self.activation == 'relu':\n",
        "            activate1 = Relu()\n",
        "            activate2 = Relu()\n",
        "        \n",
        "        #Optimisation\n",
        "        if self.solver == 'sgd':\n",
        "            optimizer1 = SGD(self.lr)\n",
        "            optimizer2 = SGD(self.lr)\n",
        "            optimizer3 = SGD(self.lr) \n",
        "        elif self.solver == 'adagrad':\n",
        "            optimizer1 = AdaGrad(self.lr)\n",
        "            optimizer2 = AdaGrad(self.lr)\n",
        "            optimizer3 = AdaGrad(self.lr)\n",
        "            \n",
        "        #重みの初期化方法の選択\n",
        "        if self.initial == 'simple':\n",
        "            initializer1 = SimpleInitializer(self.sigma)\n",
        "            initializer2 = SimpleInitializer(self.sigma)\n",
        "            initializer3 = SimpleInitializer(self.sigma)\n",
        "        elif self.initial == 'xavier':\n",
        "            initializer1 = XavierInitializer()\n",
        "            initializer2 = XavierInitializer()\n",
        "            initializer3 = XavierInitializer()\n",
        "        elif self.initial == 'he':\n",
        "            initializer1 = HeInitializer()\n",
        "            initializer2 = HeInitializer()\n",
        "            initializer3 = HeInitializer()\n",
        "        \n",
        "        #結合層および活性化関数クラスのインスタンス化\n",
        "        self.FC1 = FC(X.shape[1], self.n_nodes1, initializer1, optimizer1) #第1層\n",
        "        self.activation1 = activate1\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, initializer2, optimizer2) #第2層\n",
        "        self.activation2 = activate2\n",
        "        self.FC3 = FC(self.n_nodes2, y_onehot.shape[1], initializer3, optimizer3) #第3層\n",
        "        self.activation3 = Softmax()\n",
        "\n",
        "        self.loss_list = []       \n",
        "        self.val_loss_list= [] \n",
        "        for i in range(self.epoc):\n",
        "            self.mini_loss_list = []\n",
        "          \n",
        "            for mini_X_train, mini_y_train in train_mini_batch:\n",
        "                \n",
        "                A1 = self.FC1.forward(mini_X_train) \n",
        "                Z1 = self.activation1.forward(A1)   \n",
        "                A2 = self.FC2.forward(Z1)           \n",
        "                Z2 = self.activation2.forward(A2)   \n",
        "                A3 = self.FC3.forward(Z2)           \n",
        "                Z3 = self.activation3.forward(A3)  \n",
        "\n",
        "                dA3, mini_loss = self.activation3.backward(mini_y_train) \n",
        "                dZ2 = self.FC3.backward(dA3)         \n",
        "                dA2 = self.activation2.backward(dZ2) \n",
        "                dZ1 = self.FC2.backward(dA2)         \n",
        "                dA1 = self.activation1.backward(dZ1) \n",
        "                dZ0 = self.FC1.backward(dA1)          \n",
        "\n",
        "                self.mini_loss_list.append(mini_loss)\n",
        "                \n",
        "            loss = np.mean(self.mini_loss_list)\n",
        "            self.loss_list.append(loss)\n",
        "\n",
        "        \n",
        "            if X_val is not None and y_val is not None:\n",
        "                self.val_is_true=True\n",
        "                self.mini_val_loss_list = []\n",
        "                for mini_X_val, mini_y_val in test_mini_batch:\n",
        "\n",
        "                  \n",
        "                    A1 = self.FC1.forward(mini_X_val)\n",
        "                    Z1 = self.activation1.forward(A1)\n",
        "                    A2 = self.FC2.forward(Z1)\n",
        "                    Z2 = self.activation2.forward(A2)\n",
        "                    A3 = self.FC3.forward(Z2)\n",
        "                    Z3 = self.activation3.forward(A3)\n",
        "                    \n",
        "                    \n",
        "                    dA3, mini_val_loss = self.activation3.backward(mini_y_val) \n",
        "                    \n",
        "                    #\n",
        "                    self.mini_val_loss_list.append(mini_val_loss)\n",
        "\n",
        "                val_loss = np.mean(self.mini_val_loss_list)\n",
        "                self.val_loss_list.append(val_loss) \n",
        "\n",
        "            if self.verbose == True:\n",
        "                print('Processus d\\'apprentissage des données de formation' + str(i + 1) + 'epoc : ' + str(self.loss_list[i]))\n",
        "\n",
        "                if X_val is not None or y_val is not None:\n",
        "                    print('Processus d\\'apprentissage des données de formation' + str(i + 1) + 'epoc : ' + str(self.val_loss_list[i]))\n",
        "                    \n",
        "                \n",
        "    def predict(self, X):\n",
        "        A1 = self.FC1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        y_pred = self.activation3.forward(A3)\n",
        "        \n",
        "        return np.argmax(y_pred, axis=1)\n",
        "            \n",
        "\n",
        "    def _one_hot(self, y, n_output):\n",
        "        one_hot = np.zeros((n_output, y.shape[0]))\n",
        "\n",
        "        for idx, val in enumerate(y.astype(int)):\n",
        "            one_hot[val, idx] = 1\n",
        "\n",
        "        return one_hot.T\n",
        "    "
      ],
      "metadata": {
        "id": "5QcTydPOhmO-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problem 9] Learning and estimation"
      ],
      "metadata": {
        "id": "2iuHrFocnKdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  getting dataset"
      ],
      "metadata": {
        "id": "UetneRZunf1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "print(X_train.shape) # (48000, 784)\n",
        "print(X_val.shape) # (12000, 784)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE-GSUm8nKRk",
        "outputId": "e7ffbf94-3a42-4159-f98f-d7527101481f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n",
            "(48000, 784)\n",
            "(12000, 784)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ScratchDeepNeuralNetrowkClassifier(activation='relu', solver='sgd', initial='he',verbose=False)\n",
        "\n",
        "model.fit(X_train, y_train, X_val, y_val)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCfgvquNn4Pp",
        "outputId": "0c48a70c-ed49-48d2-dd53-620b86f68bce"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred4= model.predict(X_test)\n",
        "def plot_learning_curve(model):\n",
        "        plt.plot(range(1, model.epoc + 1), model.loss_list, color=\"r\", marker=\"o\", label=\"train loss\")\n",
        "        if model.val_is_true:\n",
        "            plt.plot(range(1, model.epoc + 1), model.val_loss_list, color=\"g\", marker=\"o\", label=\"val loss\")\n",
        "            \n",
        "        plt.title(\"Learning Curve\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.grid()\n",
        "        plt.legend(loc=\"best\")\n",
        "        plt.show()\n",
        "plot_learning_curve(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UDMQ2gMMrxsi",
        "outputId": "04ca7b0a-00f6-4201-df53-31d1e1b65914"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}