{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimplConv1d.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdeDM1+V8qJnhURKGGBig9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngeMervaneJdev/ML_AI_1/blob/main/SimplConv1d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problème 1] Création d'une classe de couche convolutionnelle unidimensionnelle qui limite le nombre de canaux à un"
      ],
      "metadata": {
        "id": "idVsICkXCSpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np;\n",
        "from scipy.sparse import dia_matrix\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "iJFPqImGcac1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkXtlSabCJi7"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SimpleConv1d:\n",
        "    def __init__(self, weight, baias):\n",
        "        self.optimizer = None\n",
        "\n",
        "        self.W = weight\n",
        "        self.B = baias\n",
        "        self.dW = None\n",
        "        self.dB = None\n",
        "        self.idx =None\n",
        "        self.X = None\n",
        "        pass\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.a = X.copy()\n",
        "        idx1 = np.arange(self.W.shape[0])\n",
        "        idx2 = np.arange(self.W.shape[0]-1 ).reshape(-1, 1)\n",
        "        self.idx = idx1 + idx2\n",
        "        A = np.sum(X[self.idx] * self.W.T,axis=1) + self.B\n",
        "        return A\n",
        "    def backward(self, dX,dA):\n",
        "\n",
        "        dB = np.sum(dA,axis=0)\n",
        "        dW = np.sum(dA[:,np.newaxis] *dX[self.idx],axis=0)\n",
        "        da = dA.reshape(-1,1)\n",
        "        data= np.repeat(da,dX.shape[0],axis=1)\n",
        "        offsets= np.arange(self.output(data))\n",
        "        d = dia_matrix((data,offsets),shape=(w.shape[0],x.shape[0])).toarray()\n",
        "        dx = np.sum(d * w[:,np.newaxis],axis=0)\n",
        "        \n",
        "        return dX\n",
        "    def output(self,X):\n",
        "        n_in = X.shape[1]\n",
        "        p = 0\n",
        "        f = self.W.shape[0]\n",
        "        s = 1 \n",
        "        n_out = ((n_in + 2*p - f)/s)+1\n",
        "        return n_out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problème 2] Calcul de la taille de sortie après convolution unidimensionnelle"
      ],
      "metadata": {
        "id": "dVAuGo-NEfTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def output(X,p,f,s):\n",
        "    n_in = X.shape[0]\n",
        "    n_out = ((n_in + 2*p - f)/s)+1\n",
        "    return n_out"
      ],
      "metadata": {
        "id": "tGh6cqtlEYOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problème 3] Expérience d'une couche convolutionnelle unidimensionnelle avec un petit réseau"
      ],
      "metadata": {
        "id": "kSgVREq-EsLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1,2,3,4])\n",
        "w = np.array([3, 5, 7])\n",
        "b = np.array([1])\n",
        "x.shape,w.shape,b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj3-M5PDcROz",
        "outputId": "dad65dd9-c52a-431e-c7f8-5ac29d701eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4,), (3,), (1,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc1 = SimpleConv1d(w,b)\n",
        "sc1.forward(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc0SCtQUc5ew",
        "outputId": "31490a6b-f038-47a9-e66e-500ec71f9b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([35, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delta_a = np.array([10, 20])\n",
        "delta_a.shape\n",
        "delta_b = np.array([30])\n",
        "delta_w = np.array([50, 80, 110])\n",
        "delta_x = np.array([30, 110, 170, 140])"
      ],
      "metadata": {
        "id": "hfdpQwKJcZRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc1 = SimpleConv1d(delta_w,delta_b)\n",
        "sc1.backward(delta_x,delta_a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN8VZZDch3GZ",
        "outputId": "c5d51890-4ccc-421c-fc0f-c0e9121b26da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 30, 110, 170, 140])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1, 2, 3, 4])\n",
        "w = np.array([3, 5, 7])\n",
        "\n",
        "a = np.empty((2, 3))\n",
        "\n",
        "indexes0 = np.array([0, 1, 2])\n",
        "indexes1 = np.array([1, 2, 3])\n",
        "\n",
        "a[0] = x[indexes0]*w # x[indexes0]は([1, 2, 3])である\n",
        "a[1] = x[indexes1]*w # x[indexes1]は([2, 3, 4])である\n",
        "\n",
        "a = a.sum(axis=1)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdunwE2AnOJj",
        "outputId": "bc2a9d65-7354-4e89-b7e9-771f88de922f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([34., 49.])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[Problème 4] Création d'une classe de couche convolutionnelle unidimensionnelle qui ne limite pas le nombre de canaux"
      ],
      "metadata": {
        "id": "tfe5OwOtj_CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # \n",
        "w = np.ones((3, 2, 3)) # \n",
        "b = np.array([1, 2, 3])"
      ],
      "metadata": {
        "id": "J6ZimcBOj-oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output2(X,p,f,s):\n",
        "    n_in = X.shape[1]\n",
        "    p = p #\n",
        "    f = f #\n",
        "    s = s #\n",
        "    n_out = ((n_in + 2*p - f)/s)+1\n",
        "    return n_out"
      ],
      "metadata": {
        "id": "KR29GVrb60bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[16, 22], [17, 23], [18, 24]])\n",
        "o = int(output2(x,0,w.shape[-1],1))\n",
        "print(o)\n",
        "\n",
        "nin, i = x.shape\n",
        "print(nin,i)\n",
        "oc, c, f = w.shape\n",
        "print(oc,c,f)\n",
        "\n",
        "#c * f \n",
        "idx_arr = np.arange(c*f).reshape(c,f)\n",
        "idx_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVA3zh6jwDwu",
        "outputId": "8ce42ee1-8150-4991-bb54-b9f12ab130d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "2 4\n",
            "3 2 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 2],\n",
              "       [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx1 = np.arange(w.shape[-1])\n",
        "\n",
        "idx2 = np.arange(w.shape[-1]-1 ).reshape(-1, 1)\n",
        "\n",
        "idx = idx1 + idx2\n",
        "\n",
        "print(x[:,idx].shape)\n",
        "a1 = x[:,idx]\n",
        "a2 = w\n",
        "print(a1)\n",
        "a= np.zeros((f,o))\n",
        "for i in range(f):\n",
        "    for j in range(o):\n",
        "        x_in = a1[j]\n",
        "        print(x_in.shape)\n",
        "        a[i][j] = np.sum(x_in @ w[i][j])\n",
        "        print('a',a.shape)\n",
        "    print(b[i].shape)\n",
        "    a[i] += a[i] + b[i]\n",
        "    print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZH_DUoF7OjL",
        "outputId": "c4f080d9-ab81-41e9-8fba-ee78e0dbab83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 2, 3)\n",
            "[[[1 2 3]\n",
            "  [2 3 4]]\n",
            "\n",
            " [[2 3 4]\n",
            "  [3 4 5]]]\n",
            "(2, 3)\n",
            "a (3, 2)\n",
            "(2, 3)\n",
            "a (3, 2)\n",
            "()\n",
            "[[31. 43.]\n",
            " [ 0.  0.]\n",
            " [ 0.  0.]]\n",
            "(2, 3)\n",
            "a (3, 2)\n",
            "(2, 3)\n",
            "a (3, 2)\n",
            "()\n",
            "[[31. 43.]\n",
            " [32. 44.]\n",
            " [ 0.  0.]]\n",
            "(2, 3)\n",
            "a (3, 2)\n",
            "(2, 3)\n",
            "a (3, 2)\n",
            "()\n",
            "[[31. 43.]\n",
            " [32. 44.]\n",
            " [33. 45.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv1d:\n",
        "    def __init__(self, initializer, optimizer, filter_num, C, filter_size):\n",
        "        self.optimizer = optimizer\n",
        "        #\n",
        "        # initializer\n",
        "        self.W = initializer.W(filter_num=filter_num, C=C, filter_size=filter_size)\n",
        "        print(self.W.shape)\n",
        "        self.B = initializer.B(filter_num)\n",
        "        \n",
        "        #\n",
        "        self.X = None\n",
        "        self.out_w = None\n",
        "\n",
        "    \n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        print(\"X==> \"+str(X.shape))\n",
        "        print(\"W==> \"+str(self.W.shape))\n",
        "        #\n",
        "        batch, C= self.X.shape #\n",
        "        FN, C, FS = self.W.shape #\n",
        "\n",
        "        #\n",
        "        self.out_w =int(self._n_out(self.W, 0.0, FS, 1.0))\n",
        "\n",
        "        #\n",
        "        A = np.zeros((batch, FN, self.out_w)) #\n",
        "        print(\"A==> \"+str(A.shape))\n",
        "        #\n",
        "        for i in range(batch):\n",
        "            #\n",
        "            for j in range(FN):\n",
        "                #\n",
        "                for k in range(C):\n",
        "                    #\n",
        "                    for l in range(self.out_w):\n",
        "                        #\n",
        "                        A[i, j, l] += np.sum(self.X[i, k, l: l + FS] * self.W[j, k, :] ) \n",
        "\n",
        "        #\n",
        "        A += self.B.reshape(1, -1, 1)\n",
        "        \n",
        "        return A\n",
        "\n",
        "    \n",
        "    def backward(self, dA):\n",
        "        FN, C, FS = self.W.shape # \n",
        "        batch, C, W = self.X.shape # \n",
        "\n",
        "        #\n",
        "        self.dW = np.zeros(self.W.shape) #\n",
        "        dX = np.zeros(self.X.shape) #\n",
        "\n",
        "        #\n",
        "        for i in range(batch):\n",
        "            #\n",
        "            for j in range(FN):\n",
        "                #\n",
        "                for k in range(C):\n",
        "                    #\n",
        "                    for l in range(FS):\n",
        "                        #\n",
        "                        for m in range(self.out_w):\n",
        "                            #足しあげる\n",
        "                            self.dW[j, k, l] += dA[i, j, m] * self.X[i, k, l + m]\n",
        "                            dX[i, k, l + m] += dA[i, j, m] * self.W[j, k, l]\n",
        "\n",
        "        self.dB = dA.sum(axis=2)\n",
        "        self = self.optimizer.update(self)\n",
        "        \n",
        "        return dX\n",
        "\n",
        "    \n",
        "    def _n_out(self, n_in, p, f, s):\n",
        "          n_in = self.X.shape[1]\n",
        "          p = p #\n",
        "          f = f #\n",
        "          s = s #\n",
        "          n_out = ((n_in + 2*p - f)/s)+1\n",
        "          return n_out"
      ],
      "metadata": {
        "id": "Dz4-cTwS-PYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FC:\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = initializer.B(n_nodes2)\n",
        "\n",
        "    \n",
        "    def forward(self, Z1):\n",
        "        self.Z = Z1.copy()\n",
        "        Z2 = np.dot(Z1, self.W) + self.B\n",
        "        \n",
        "        return Z2\n",
        "    \n",
        "    \n",
        "    def backward(self, dA):\n",
        "        self.dB = dA \n",
        "        self.dW = np.dot(self.Z.T, dA) \n",
        "        dZ = np.dot(dA, self.W.T) \n",
        "        \n",
        "        self = self.optimizer.update(self)\n",
        "        \n",
        "        return dZ"
      ],
      "metadata": {
        "id": "HOD2wMfZjx2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]        \n",
        "\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]"
      ],
      "metadata": {
        "id": "NkZK8LeiQWT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Flat():\n",
        "    def __init__(self):\n",
        "        self.X_shape = None\n",
        "    \n",
        "    def forward(self, X):\n",
        "        X_1d = X.reshape(X.shape[0], -1)\n",
        "        \n",
        "        self.X_shape = X.shape\n",
        "        \n",
        "        return X_1d\n",
        "\n",
        "    def backward(self, X):\n",
        "        X = X.reshape(self.X_shape)\n",
        "        \n",
        "        return X"
      ],
      "metadata": {
        "id": "m-tMBy6fR8vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tanh:\n",
        "    def __init__(self):\n",
        "        self.Z = None\n",
        "    \n",
        "    def forward(self, A):\n",
        "        self.Z =  np.tanh(A)\n",
        "        \n",
        "        return  self.Z\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        dA = dZ * (1 - self.Z**2)\n",
        "        \n",
        "        return dA"
      ],
      "metadata": {
        "id": "XcKPVd6sVvCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class XavierInitializer:\n",
        "    def __init__(self):\n",
        "        pass    \n",
        "    def W(self, n_nodes1=None, n_nodes2=None, \n",
        "                  filter_num=None, C=None, filter_size=None):\n",
        "        #\n",
        "        if filter_num and C and filter_size is not None:\n",
        "            W =  np.random.randn(filter_num, C, filter_size) / np.sqrt(filter_num)\n",
        "        #\n",
        "        else:\n",
        "            W = np.random.randn(n_nodes1, n_nodes2) / np.sqrt(n_nodes1) \n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        B = np.zeros(n_nodes2) \n",
        "        \n",
        "        return B"
      ],
      "metadata": {
        "id": "uCQegX7EVrbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.Z = None \n",
        "    def forward(self, A):\n",
        "        self.Z = 1 / (1 + np.exp(-A))\n",
        "        return self.Z\n",
        "    def backward(self, dZ):\n",
        "        dA = dZ * (1 - self.Z) * self.Z\n",
        "        return dA"
      ],
      "metadata": {
        "id": "MJLMi0tnVztM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HeInitializer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def W(self, n_nodes1=None, n_nodes2=None,filter_num=None, C=None, filter_size=None):\n",
        "      \n",
        "        if filter_num and C and filter_size is not None:\n",
        "            W = np.random.randn(filter_num, C, filter_size) * np.sqrt(2 / filter_num)\n",
        "        else:\n",
        "            W = np.random.randn(n_nodes1, n_nodes2) * np.sqrt(2 / n_nodes1)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = np.zeros(n_nodes2) \n",
        "        return B"
      ],
      "metadata": {
        "id": "EMHOnCrEVnXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr \n",
        "        self.H_W= None \n",
        "        self.H_B = None\n",
        "\n",
        "    def update(self, layer):\n",
        "        if self.H_W is None:\n",
        "            self.H_W = np.zeros(layer.W.shape)\n",
        "        if self.H_B is None:\n",
        "            self.H_B = np.zeros(layer.B.shape)\n",
        "        \n",
        "        self.H_W += (layer.dW / layer.dB.shape[0]) ** 2 \n",
        "        self.H_B += (layer.dB.mean(axis=0)) **2\n",
        "        layer.W -= self.alpha / np.sqrt(self.H_W + 1e-7) * layer.dW / layer.dB.shape[0] \n",
        "        layer.B -= self.alpha / np.sqrt(self.H_B + 1e-7) * layer.dB.mean(axis=0) \n",
        "        \n",
        "        return layer"
      ],
      "metadata": {
        "id": "iaya9vvoVhO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "    def __init__(self):\n",
        "        self.X = None\n",
        "    def forward(self, A):\n",
        "        self.X = A.copy()\n",
        "        Z = np.maximum(0, A)\n",
        "        return Z\n",
        "    def backward(self, dZ):\n",
        "        dA = np.where(self.X > 0, dZ, 0)\n",
        "        return dA"
      ],
      "metadata": {
        "id": "UhM8XSu9WSOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "        ## layer.dB=partial derivatives of loss\n",
        "        layer.W -= self.lr* layer.dW / layer.dB.shape[0] #(n_nodes1, n_nodes2)\n",
        "        layer.B -= self.lr* layer.dB.mean(axis=0) #(n_nodes2)"
      ],
      "metadata": {
        "id": "TtMbyj2XWNF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax:\n",
        "    def __init__(self):\n",
        "        self.Z = None\n",
        "    \n",
        "    def forward(self, A):\n",
        "        c = np.max(A)\n",
        "        exp_A = np.exp(A - c)\n",
        "        sum_exp_A = np.sum(exp_A, axis=1).reshape(-1, 1)\n",
        "\n",
        "        self.Z = exp_A / sum_exp_A  \n",
        "        return self.Z\n",
        "\n",
        "    def backward(self, y):\n",
        "        loss_sum = np.sum(y * np.log(self.Z), axis=1)\n",
        "        loss = -np.mean(loss_sum)\n",
        "        \n",
        "        dA = self.Z - y    \n",
        "        return dA"
      ],
      "metadata": {
        "id": "G_8vyYLvV6mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma \n",
        "        \n",
        "\n",
        "    def W(self, n_nodes1=None, n_nodes2=None,filter_num=None, C=None, filter_size=None):\n",
        "\n",
        "        if filter_num is not None and C is not None and filter_size is not None:\n",
        "            W =  self.sigma * np.random.randn(filter_num, C, filter_size) \n",
        "        if n_nodes1 is not None and n_nodes2 is not None:\n",
        "            W =  self.sigma * np.random.randn(n_nodes1, n_nodes2) \n",
        "        return W\n",
        "    \n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        B = np.zeros(n_nodes2) \n",
        "        return B"
      ],
      "metadata": {
        "id": "3KD9hYb9b8YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Scratchch1dCNNNeuralNetrowkClassifier():\n",
        "    def __init__(self, epoc=10, activation='relu', solver='adagrad', alpha=0.005, batch_size=10, initial='he', sigma=0.01, n_nodes1=50,n_nodes2=25, filter_num=3,  filter_size=7, verbose=True):\n",
        "        self.epoc= epoc  \n",
        "        self.activation=activation \n",
        "        self.solver=solver \n",
        "        self.alpha=alpha\n",
        "        self.batch_size=batch_size\n",
        "        self.initial=initial    \n",
        "        self.sigma=sigma         \n",
        "        self.n_nodes1=n_nodes1  \n",
        "        self.n_nodes2=n_nodes2   \n",
        "        self.filter_num=filter_num   \n",
        "        self.filter_size=filter_size    \n",
        "        self.verbose=verbose        \n",
        "        \n",
        "        \n",
        "        self.conv1=None\n",
        "        self.FC1= None \n",
        "        self.FC2= None\n",
        "        self.activation1= None \n",
        "        self.activation2= None\n",
        "        self.activation3= None \n",
        "        self.loss_list= None \n",
        "        self.mini_loss_list= None \n",
        "        self.val_loss_list= None\n",
        "        self.mini_loss_list= None \n",
        "        self.flat=None\n",
        "    \n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "\n",
        "        #one_hot\n",
        "        n_output = np.unique(y).shape[0]\n",
        "        y_onehot = self._one_hot(y, n_output)\n",
        "        \n",
        "        #\n",
        "        train_mini_batch = GetMiniBatch(X, y_onehot, self.batch_size)\n",
        "        \n",
        "        #val\n",
        "        if X_val is not None and y_val is not None:       \n",
        "            y_val_onehot = self._one_hot(y_val, n_output) #one-hot\n",
        "            test_mini_batch = GetMiniBatch(X_val, y_val_onehot) #\n",
        "        \n",
        "        \n",
        "        #\n",
        "        if self.activation == 'sigmoid':\n",
        "            activate1 = Sigmoid()\n",
        "            activate2 = Sigmoid()\n",
        "            activate3 = Sigmoid()\n",
        "        elif self.activation == 'tanh':\n",
        "            activate1 = Tanh()\n",
        "            activate2 = Tanh()\n",
        "            activate3 = Tanh()\n",
        "        elif self.activation == 'relu':\n",
        "            activate1 = ReLU()\n",
        "            activate2 = ReLU()\n",
        "            activate3 = ReLU()\n",
        "\n",
        "        \n",
        "        #\n",
        "        if self.solver == 'sgd':\n",
        "            optimizer1 = SGD(self.alpha)\n",
        "            optimizer2 = SGD(self.alpha)\n",
        "            optimizer3 = SGD(self.alpha) \n",
        "            optimizer4 = SGD(self.alpha)\n",
        "            optimizer5 = SGD(self.alpha) \n",
        "        elif self.solver == 'adagrad':\n",
        "            optimizer1 = AdaGrad(self.alpha)\n",
        "            optimizer2 = AdaGrad(self.alpha)\n",
        "            optimizer3 = AdaGrad(self.alpha)\n",
        "            optimizer4 = AdaGrad(self.alpha)\n",
        "            optimizer5 = AdaGrad(self.alpha)\n",
        "            \n",
        "        #\n",
        "        if self.initial == 'simple':\n",
        "            initializer1 = SimpleInitializer(self.sigma)\n",
        "            initializer2 = SimpleInitializer(self.sigma)\n",
        "            initializer3 = SimpleInitializer(self.sigma)\n",
        "            initializer4 = SimpleInitializer(self.sigma)\n",
        "            initializer5 = SimpleInitializer(self.sigma)\n",
        "        elif self.initial == 'xavier':\n",
        "            initializer1 = XavierInitializer()\n",
        "            initializer2 = XavierInitializer()\n",
        "            initializer3 = XavierInitializer()\n",
        "            initializer4 = XavierInitializer()\n",
        "            initializer5 = XavierInitializer()\n",
        "        elif self.initial == 'he':\n",
        "            initializer1 = HeInitializer()\n",
        "            initializer2 = HeInitializer()\n",
        "            initializer3 = HeInitializer()\n",
        "            initializer4 = HeInitializer()\n",
        "            initializer5 = HeInitializer()\n",
        "\n",
        "        #\n",
        "        self.conv1 = Conv1d(initializer1, optimizer1, self.filter_num, X.shape[1], self.filter_size)\n",
        "        self.activation1 = activate1\n",
        "        \n",
        "        #\n",
        "        self.flat = Flat()\n",
        "        out = self.filter_num * (X.shape[1] - (self.filter_size - 1))\n",
        "\n",
        "        #\n",
        "        self.FC1 = FC(out, self.n_nodes1, initializer2, optimizer2) \n",
        "        self.activation2 = activate2\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, initializer3, optimizer3) \n",
        "        self.activation3 = activate3\n",
        "        self.FC3 = FC(self.n_nodes2, y_onehot.shape[1], initializer4, optimizer4)\n",
        "        self.activation4 = Softmax()\n",
        "        \n",
        "        #\n",
        "        self.loss_list=[]\n",
        "        self.val_loss_list=[]\n",
        "        \n",
        "        #\n",
        "        for i in range(self.epoc):\n",
        "            \n",
        "            #\n",
        "            self.mini_loss_list = []\n",
        "            \n",
        "            #\n",
        "            for mini_X_train, mini_y_train in train_mini_batch:\n",
        "                \n",
        "                #\n",
        "                A1 = self.conv1.forward(mini_X_train) \n",
        "                Z1 = self.activation1.forward(A1)    \n",
        "                F1 = self.flat.forward(Z1)\n",
        "                \n",
        "                #\n",
        "                A2 = self.FC1.forward(F1)                   \n",
        "                Z2 = self.activation2.forward(A2) \n",
        "                A3 = self.FC2.forward(Z2)             \n",
        "                Z3 = self.activation3.forward(A3)\n",
        "                A4 = self.FC3.forward(Z3)             \n",
        "                Z4 = self.activation4.forward(A4)   \n",
        "                \n",
        "                #\n",
        "                dA4, mini_loss = self.activation4.backward(mini_y_train) \n",
        "                dZ4 = self.FC3.backward(dA4)          \n",
        "                dA3 = self.activation3.backward(dZ4) \n",
        "                dZ3 = self.FC2.backward(dA3)            \n",
        "                dA2 = self.activation2.backward(dZ3) \n",
        "                dZ2 = self.FC1.backward(dA2)    \n",
        "                \n",
        "                #\n",
        "                dF1 = self.flat.backward(dZ2)\n",
        "                \n",
        "                \n",
        "                dA2 = self.activation1.backward(dF1)\n",
        "                dZ1 = self.conv1.backward(dA2)\n",
        "\n",
        "                #\n",
        "                self.mini_loss_list.append(mini_loss)\n",
        "\n",
        "            #\n",
        "            loss = np.mean(self.mini_loss_list)\n",
        "            self.loss_list.append(loss)\n",
        "\n",
        "            \n",
        "            #\n",
        "            if X_val is not None and y_val is not None:\n",
        "                \n",
        "                self.mini_val_loss_list = []\n",
        "                for mini_X_val, mini_y_val in test_mini_batch:\n",
        "              \n",
        "                    #\n",
        "                    A1 = self.conv1.forward(mini_X_val)\n",
        "                    Z1 = self.activation1.forward(A1)\n",
        "                    F1 = self.flat.forward(Z1)\n",
        "                    A2 = self.FC1.forward(F1)\n",
        "                    Z2 = self.activation2.forward(A2)\n",
        "                    A3 = self.FC2.forward(Z2)\n",
        "                    Z3 = self.activation3.forward(A3)\n",
        "                    A4 = self.FC3.forward(Z3) \n",
        "                    Z4 = self.activation4.forward(A4)\n",
        "\n",
        "                    #\n",
        "                    _, mini_val_loss = self.activation4.backward(mini_y_val)\n",
        "                    self.mini_val_loss_list.append(mini_val_loss)\n",
        "\n",
        "                val_loss = np.mean(self.mini_val_loss_list)\n",
        "                self.val_loss_list.append(val_loss)\n",
        "\n",
        "                \n",
        "            #\n",
        "            if self.verbose == True:\n",
        "                print('Processus d\\'apprentissage des données de vérification' + str(i + 1) + 'epoc : ' + str(self.loss_list[i]))\n",
        "                #\n",
        "            if X_val is not None or y_val is not None:\n",
        "                print('Processus d\\'apprentissage des données de vérification' + str(i + 1) + 'epoc: ' + str(self.val_loss_list[i]))\n",
        "                    \n",
        "                \n",
        "    def predict(self, X):\n",
        "    \n",
        "        #\n",
        "        A1 = self.conv1.forward(X) \n",
        "        Z1 = self.activation1.forward(A1) \n",
        "        \n",
        "        #\n",
        "        F1 = self.flat.forward(Z1)\n",
        "        \n",
        "        #\n",
        "        A2 = self.FC1.forward(F1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC2.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        A4 = self.FC3.forward(Z3)\n",
        "        y_pred = self.activation4.forward(A4)  \n",
        "                       \n",
        "        return np.argmax(y_pred, axis=1)\n",
        "            \n",
        "\n",
        "    def _one_hot(self, y, n_output):\n",
        "        #\n",
        "        one_hot = np.zeros((n_output, y.shape[0]))\n",
        "        \n",
        "        #\n",
        "        for idx, val in enumerate(y.astype(int)):\n",
        "            one_hot[val, idx] = 1\n",
        "\n",
        "        return one_hot.T"
      ],
      "metadata": {
        "id": "r2gLP06hXKsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "print(X_train.shape) # (48000, 784)\n",
        "print(X_val.shape) # (12000, 784)"
      ],
      "metadata": {
        "id": "D8rrgIP0bjET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc7c00d2-325a-4f24-be5a-2229cb4a2b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n",
            "(48000, 784)\n",
            "(12000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Scratchch1dCNNNeuralNetrowkClassifier()\n",
        "\n",
        "model.fit(X_train,y_train,X_val,y_val)"
      ],
      "metadata": {
        "id": "zDiE8Ygcbl5n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "7b38fd83-d884-4b4f-d6f1-4a64114b13f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 784, 7)\n",
            "X==> (10, 784)\n",
            "W==> (3, 784, 7)\n",
            "A==> (10, 3, 778)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-00c81af0f885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScratchch1dCNNNeuralNetrowkClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-2e549e4871ed>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_X_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mF1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-f6c933a42147>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                         \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFS\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
          ]
        }
      ]
    }
  ]
}